---
title: "Titanic XGBoosting"
navbar:
  title: "Simon Raymond"
  left:
    - text: "Home"
      href: index.html
    - text: "About"
      href: about.html
    - text: "Titanic XGBoosting"
      href: Titanic_XGBoosting.html
    - text: "Titanic Adaboost"
      href: Titanic_Adaboost.html
    - text: "Titanic Nnet"
      href: Titanic_Nnet.html
    - text: "Titanic_LM_CART_and_RF"
      href: Titanic_LM_CART_RF.html
      name: SimonRaymond 
---




This will be the file for my titanic xgb

# Data Prep
Download the Data
```{r, warning=FALSE}
library(readr)

train_titanic <- read_csv("train.csv")
```

The collums i will use are y, Pclass, Sec, Age, SibSp, Parch, Fare, Emarked as they are the easiest to work with. other possibilities include using the titles for names 
```{r}
library(dplyr)

selected_cols <- c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked")
data <- train_titanic[selected_cols]
data <- data %>% rename(y = Survived)
```

convert the characters to factors. convert our y variable to numeric for XGBoosting
```{r, warning=FALSE}
char_cols <- sapply(data, is.character)
data[, char_cols] <- lapply(data[, char_cols], factor)
data$y <- as.numeric(data$y)

```

we have NAs we need to deal with
```{r, warning=FALSE}
colSums(is.na(data))
```

First i am going to predict the NAs for Age with a simple Random Forest model.
```{r, warning=FALSE}
na_index <- which(is.na(data$Age))#index the missing NAs
na_data <- data[na_index, ]#create a data frame of the NAs indexed
c_data <-data[-na_index, ]#take the complete data to c_data
na_data <- na_data[, -which(names(data) == "Age")] # take out the collum that only has NAs in it
```

 i will use na.roughfix() for the two missing Embarked values
```{r, warning=FALSE}
library(randomForest)

c_data <- na.roughfix(c_data)# there are two NAs in embarked
na_data <-  na.roughfix(na_data)
```

Predict our NAs
```{r, warning=FALSE}
library(randomForest)

model_rf <- randomForest(Age ~.,
                         ntree = 1200, 
                         data = c_data) 

pred_na <- predict(model_rf, na_data)
```

This binds our predictions to the corresponding index number for each missing NA in "data"
```{r, warning=FALSE}
na_n_ind <- cbind(pred_na, na_index)

data$Age[na_n_ind[, 2]] <- na_n_ind[, 1]
```

finnaly just use na.roughfix() for the two embarked values in the actualy data sets
```{r, warning=FALSE}
library(randomForest)

data <- na.roughfix(data)
colSums(is.na(data))
```

```{r, warning=FALSE}
str(data)
```

# xgBoosting 

This code performs hyperparameter tuning for an XGBoost model. The number of iterations is controlled by the variable n. At each iteration, the code samples s hyperparameter combinations from a pre-defined grid. Then, the data is split into modeling and test data sets. the modeling data is boostrapped to make train and val data sets to to be used to select hyperparameters to be tested.

For each hyperparameter combination, the average area under the curve (AUC) is calculated across the v validation runs. The hyperparameter combination with the highest average AUC is selected as the best hyperparameters for that iteration. The selected hyperparameters and their corresponding AUC are stored in the opt matrix.

Finally, the code trains an XGBoost model on the modeldata(both train and val) set using the best hyperparameters from each iteration. The AUC of that model is evaluated on a hold-out test set, and the results are stored in opt. 

Note that the hyperparameters being tuned are nrounds, max_depth, eta, subsample, colsample_bytree, gamma, min_child_weight, alpha, and lambda. The nthread parameter controls the number of threads to use during training.

This grid is very limited because of processing power. it is relatively tuned.
```{r, warning=FALSE}
grid <- expand.grid(
  nrounds = seq(300, 300, by = 0),
  max_depth = seq(13, 16, by = 2),
  eta = seq(0.1, 0.2, by = 0.01),
  subsample = seq(0.7, 0.8, by = 0.1),
  colsampe_bytree = seq(0.7, 0.8, by = 0.1),
  gamma = seq(1, 2, by = 1),
  min_child_weight = seq(0, 5, by = 2),
  alpha = seq(0, 1, by = 1),
  lambda = seq(0, 1, by = 1)
)
```

```{r, warning=FALSE}
library(xgboost)
library(ROCR)

start_time <- Sys.time()

n <- 50 # how many times we repeat the algorithm
s <- 500 # how many hyperparamter sets are validated, length of randomgrid
v <- 10 # how many times we bootstrapped a sample for each hyperparameter set


esr <- 5
opt <- matrix(0, nrow = n, ncol = 11, dimnames = list(NULL, c("nrounds", "max_depth", "eta", "subsample", "colsampe_bytree", "gamma", "min_child_weight", "alpha", "lambda", "val_AUC", "Test_AUC")))

auc_t <- c()
for(j in 1:n){
  
  # this makes the random grid by sampling from grid s times
  ind <- sample(nrow(grid), s, replace = FALSE)
  rgrid <- grid[ind, ]
  
  #  this creates model data and test data
  ind1 <- sample(nrow(data), nrow(data)*0.8)
  md <- data[ind1, ]
  test <- data[-ind1, ]
  
  v_auc_mean <- c()
  for (i in 1:nrow(rgrid)) {
    auc_tuning <- c()
for (p in 1:v){
  
  #cat("loops: ", j, i, p, "\r")
  
  # bootstrap for samples
  ind2 <- unique(sample(nrow(md), nrow(md), replace = TRUE))
  train <- md[ind2, ]
  val <- md[-ind2, ]

  # One-hot coding using R's `model.matrix`
  train_x <- model.matrix(~.+0, data = train[, -which(names(train) == "y")]) 
  train_y <- train$y
 
  val_x <- model.matrix(~.+0, data = val[, -which(names(val) == "y")])
  val_y <- val$y
  
  # Preparing efficient matrix
  xgb_train <- xgb.DMatrix(data = train_x, label = train_y) 
  xgb_val <- xgb.DMatrix(data = val_x, label = val_y)

  # Training the model on train data
  xgb_model <- xgb.train(params = list(objective = "binary:logistic"),
                         data = xgb_train, 
                         nrounds = rgrid[i, 1],
                         max_depth = rgrid[i, 2],
                         eta = rgrid[i, 3], 
                         subsample = rgrid[i, 4],
                         colsample_bytree = rgrid[i, 5],
                         gamma = rgrid[i, 6],
                         min_child_weight = rgrid[i, 7],
                         alpha = rgrid[i, 8],
                         lambda = rgrid[i, 9],
                         early_stopping_rounds = esr,
                         eval_metric = "auc",
                         watchlist = list(train = xgb_train, val = xgb_val),
                         verbose = FALSE,
                         nthread = 3
  )

  
# Predicting on the val data
phat <- predict(xgb_model, xgb_val, type = "prob")

  # Calculating the AUC
  pred_rocr <- prediction(phat, val_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc_tuning[p] <- auc_ROCR@y.values[[1]]
}
    
# get the mean of the hyperparamters(set) that was just run
v_auc_mean[i] <- mean(auc_tuning)



 BI <- which.max(v_auc_mean) #best hyperparameter index
  best_AUC <- v_auc_mean[BI]
  best_params <- rgrid[BI, ]
  
  # store the best hyperparameters and there val results
  opt[j, 1] <- best_params[1, 1]
  opt[j, 2] <- best_params[1, 2]
  opt[j, 3] <- best_params[1, 3]
  opt[j, 4] <- best_params[1, 4]
  opt[j, 5] <- best_params[1, 5]
  opt[j, 6] <- best_params[1, 6]
  opt[j, 7] <- best_params[1, 7]
  opt[j, 8] <- best_params[1, 8]
  opt[j, 9] <- best_params[1, 9]
  opt[j, 10] <- max(v_auc_mean)
}

  # One-hot coding using R's `model.matrix` for the final test
  md_x <- model.matrix(~.+0, data = md[, -which(names(md) == "y")]) 
  md_y <- md$y
 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  test_y <- test$y
  
  # Preparing efficient matrix for the final test
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  
  
  
  # Train the model with model data
  xgb_mt <- xgb.train(params = list(objective = "binary:logistic"),
                         data = xgb_md, 
                         nrounds = opt[j ,1],
                         max_depth = opt[j ,2],
                         eta = opt[j ,3], 
                         subsample = opt[j ,4],
                         colsample_bytree = opt[j ,5],
                         gamma = opt[j ,6],
                         min_child_weight = opt[j ,7],
                         alpha = opt[j ,8],
                         lambda = opt[j ,9],
                         early_stopping_rounds = esr,
                         eval_metric = "auc",
                         watchlist = list(train = xgb_md, val = xgb_test),
                         verbose = FALSE,
                         nthread = 3
  )

  
# Predicting on the test set
phat <- predict(xgb_mt, xgb_test, type = "prob")

  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc_t <- auc_ROCR@y.values[[1]]


# store the test auc
opt[j, 11] <- auc_t
  
}



end_time <- Sys.time()

elapsed_time <- end_time - start_time

elapsed_time
 


```
This code will index and assign the best hyper parameters from opt into a matrix called win. 

NOTE: A weakness is that the test run is one split or rather one n run. this means it is weak to a high standard deviation or variability in the models predicition. This issue starts to dissapear as we can run the model more times (n) as we then can look for similar hyper parameter sets and select based on there mean test scores. 

This takes the top 50 percent of hyperparameters based on there test scores and puts them into a matrix named win
```{r, warning=FALSE}

th <- quantile(opt[,11], probs = 0.50)
ind_opt <- which(opt[,11] >= th)

win <- opt[ind_opt, ]
win
```

This code is using bootstrapping and runs the best hyperparamters that we picked before. it tests the selected hyper parameters n times. since we are not tuning in it we can use all of the data in it.
```{r, warning=FALSE}
library(xgboost)
library(ROCR)

n <- 400
w <- nrow(win)
esr <- 10 # early stopping rounds

#collums are hyper param set
bs_results <- matrix(0, nrow = n, ncol = w)



for (i in 1:n) {
  for (j in 1:w){
    auc <- c()
  #cat("loops: ", i, j, "\r")
  
  # Initial Split
  ind <- unique(sample(nrow(data), nrow(data), replace = TRUE))
  mdf<- data[ind, ]
  test <- data[-ind, ]
  
  # One-hot coding using R's `model.matrix`
  md_y <- mdf$y
  test_y <- test$y
  md_x <- model.matrix(~.+0, data = mdf[, -which(names(mdf) == "y")]) 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  
  # Preparing efficient matrix
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  # Training and evaluating the model
  xgb_m <- xgb.train(params = list(objective = "binary:logistic"),
                               data = xgb_md, 
                               nrounds = win[j, 1],
                               max_depth = win[j, 2],
                               eta = win[j, 3], 
                               subsample = win[j, 4],
                               colsample_bytree = win[j, 5],
                               gamma = win[j, 6],
                               min_child_weight = win[j, 7],
                               alpha = win[j, 8],
                               lambda = win[j, 9],
                               early_stopping_rounds = esr,
                               eval_metric = "auc",
                               watchlist = list(train = xgb_md, val = xgb_test),
                               verbose = FALSE,
                               nthread = 3
                              
  )
  
  # Predicting on the test set
  phat <- predict(xgb_m, xgb_test, type = "prob")
  
  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc <- auc_ROCR@y.values[[1]]
  
  # matrix with n rows and w collums. each collum is a hyper parameter
 bs_results[i, j] <- auc 
}
}
```

This code takes the colmeans of the matrix that gave our results. then we bind these results onto the win matrix for presentation. it also takes the index of the best run from before and saves the correlating hyperparameters into bh.
```{r, warning=FALSE}
bh_ind <- which.max(colMeans(bs_results))
bh <- win[bh_ind, ]
mean(bs_results[,bh_ind])
cm <- as.vector(colMeans(bs_results))
win <- cbind(win, av_ovr_n_runs=cm)
```

This is the final run. it uses bootstrapping and runs n times. This is mostly to do a final proof and present the auc 
```{r, warning=FALSE}
library(xgboost)
library(ROCR)

n <- 1000

esr <- 10

 auc <- c()
for (i in 1:n) {

   
  #cat("loops: ", i, "\r")
  
  # Initial Split This is bootstrapping
  ind <- unique(sample(nrow(data), nrow(data), replace = TRUE))
  mdf<- data[ind, ]
  test <- data[-ind, ]
  
  # One-hot coding using R's `model.matrix`
  md_y <- mdf$y
  test_y <- test$y
  md_x <- model.matrix(~.+0, data = mdf[, -which(names(mdf) == "y")]) 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  
  # Preparing efficient matrix
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  # Modeling with md
  xgb_m <- xgb.train(params = list(objective = "binary:logistic"),
                               data = xgb_md, 
                               nrounds = bh[1],
                               max_depth = bh[2],
                               eta = bh[3], 
                               subsample = bh[4],
                               colsample_bytree = bh[5],
                               gamma = bh[6],
                               min_child_weight = bh[7],
                               alpha = bh[8],
                               lambda = bh[9],
                               early_stopping_rounds = esr,
                               eval_metric = "auc",
                               watchlist = list(train = xgb_md, val = xgb_test),
                               verbose = FALSE,
                               nthread = 3
                              
  )
  
  # Predicting on the test set
  phat <- predict(xgb_m, xgb_test, type = "prob")
  
  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc[i] <- auc_ROCR@y.values[[1]]
}
 
 mean(auc)
 sd(auc)
```

This presents the mean and 95% CI of the model runs
Note: we are representing individual observations/model runs so we use SD not SE.   
                             
```{r, warning=FALSE}

# plot auc and 95% CI of the runs
plot(auc, col="red")
abline(a = mean(auc), b = 0, col = "blue", lwd = 2)
abline(a = mean(auc)-1.96*sd(auc), b = 0, col = "green", lwd = 3)
abline(a = mean(auc)+1.96*sd(auc), b = 0, col = "green", lwd = 3)

```

If we are finding a threshold he then need to pay attention to the watchlist outputs and tune nrounds accordingly. 
also note i am use early stopping rounds in my loops.

---
title: "Titanic XGBoosting"
navbar:
  title: "Simon Raymond"
  left:
    - text: "Home"
      href: index.html
    - text: "About"
      href: about.html
    - text: "Titanic XGBoosting"
      href: Titanic_XGBoosting.html
    - text: "Titanic Adaboost"
      href: Titanic_Adaboost.html
    - text: "Titanic Nnet"
      href: Titanic_Nnet.html
    - text: "Titanic_LM_CART_and_RF"
      href: Titanic_LM_CART_RF.html
      name: SimonRaymond 
---




This will be the file for my titanic xgb

# Data Prep
Download the Data
```{r}
library(readr)

train_titanic <- read_csv("train.csv")
```

The collums i will use are y, Pclass, Sec, Age, SibSp, Parch, Fare, Emarked as they are the easiest to work with. other possibilities include using the titles for names 
```{r}
library(dplyr)

data <- train_titanic[ ,c(2, 3, 5, 6, 7, 8, 10, 12)]
data <- data %>% rename(y = Survived)



```

convert the characters to factors. convert our y variable to numeric for XGBoosting
```{r}
char_cols <- sapply(data, is.character)
data[, char_cols] <- lapply(data[, char_cols], factor)
data$y <- as.numeric(data$y)

```

we have NAs we need to deal with
```{r}
colSums(is.na(data))
```

First i am going to predict the NAs for Age with a simple Random Forest model.
```{r}
na_index <- which(is.na(data$Age))#index the missing NAs
na_data <- data[na_index, ]#create a data frame of the NAs indexed
c_data <-data[-na_index, ]#take the complete data to c_data
na_data <- na_data[, -which(names(data) == "Age")] # take out the collum that only has NAs in it
```

 i will use na.roughfix() for the two missing Embarked values
```{r}
library(randomForest)

c_data <- na.roughfix(c_data)# there are two NAs in embarked
na_data <-  na.roughfix(na_data)
```

Predict our NAs
```{r}
library(randomForest)

model_rf <- randomForest(Age ~.,
                         ntree = 1200, 
                         data = c_data) 

pred_na <- predict(model_rf, na_data)
```

This binds our predictions to the corresponding index number for each missing NA in "data"
```{r}
na_n_ind <- cbind(pred_na, na_index)

data$Age[na_n_ind[, 2]] <- na_n_ind[, 1]
```

finnaly just use na.roughfix() for the two embarked values in the actualy data sets
```{r}
library(randomForest)

data <- na.roughfix(data)
colSums(is.na(data))
```

```{r}
str(data)
```

# xgBoosting 

This code performs hyperparameter tuning for an XGBoost model using a bootstrapping approach. The number of iterations is controlled by the variable n. At each iteration, the code samples s hyperparameter combinations from a pre-defined grid. Then, the data is split into training and validation sets, and the selected hyperparameters are evaluated v times on the validation set.

For each hyperparameter combination, the average area under the curve (AUC) is calculated across the v validation runs. The hyperparameter combination with the highest average AUC is selected as the best hyperparameters for that iteration. The selected hyperparameters and their corresponding AUC are stored in the opt matrix.

Finally, the code trains an XGBoost model on the entire model data set using the best hyperparameters from each iteration. The AUC of the trained model is evaluated on a hold-out test set, and the results are stored in opt. A weakness i have found is that the final test on be validated hyperparameters is only preformed once since the data is kept seperate.

Note that the hyperparameters being tuned are nrounds, max_depth, eta, subsample, colsample_bytree, gamma, min_child_weight, alpha, and lambda. The nthread parameter controls the number of threads to use during training.

Overall, this code can be useful for finding the best set of hyperparameters for an XGBoost model. The bootstrapping approach can help mitigate overfitting, and the use of a pre-defined grid can help avoid an exhaustive search of the hyperparameter space.

This grid is very limited because of processing power. it is relativly tuned.
```{r}
grid <- expand.grid(
  nrounds = seq(300, 300, by = 100),
  max_depth = seq(13, 16, by = 2),
  eta = seq(0.1, 0.2, by = 0.01),
  subsample = seq(0.7, 0.8, by = 0.1),
  colsampe_bytree = seq(0.7, 0.8, by = 0.1),
  gamma = seq(1, 2, by = 1),
  min_child_weight = seq(0, 2, by = 1),
  alpha = seq(0, 1, by = 1),
  lambda = seq(0, 1, by = 1)
)
```

```{r}
library(xgboost)
library(ROCR)

start_time <- Sys.time()

n <- 15
s <- 250
v <- 5
esr <- 10
opt <- matrix(0, nrow = n, ncol = 11, dimnames = list(NULL, c("nrounds", "max_depth", "eta", "subsample", "colsampe_bytree", "gamma", "min_child_weight", "alpha", "lambda", "val_AUC", "Test_AUC")))

auc_t <- c()
for(j in 1:n){
  
    

  
  ind <- sample(nrow(grid), s, replace = FALSE)
  rgrid <- grid[ind, ]
  

  ind1 <- sample(nrow(data), nrow(data)*0.8)
  md <- data[ind1, ]
  test <- data[-ind1, ]
  
  auc_runs <- c()
  for (i in 1:nrow(rgrid)) {
    auc_tuning <- c()
for (p in 1:v){
  
  #cat("loops: ", j, i, p, "\r")
  
  # Initial Split
  ind2 <- unique(sample(nrow(md), nrow(md), replace = TRUE))
  train <- md[ind2, ]
  val <- md[-ind2, ]

  # One-hot coding using R's `model.matrix`
  train_x <- model.matrix(~.+0, data = train[, -which(names(train) == "y")]) 
  train_y <- train$y
 
  val_x <- model.matrix(~.+0, data = val[, -which(names(val) == "y")])
  val_y <- val$y
  
  # Preparing efficient matrix
  xgb_train <- xgb.DMatrix(data = train_x, label = train_y) 
  xgb_val <- xgb.DMatrix(data = val_x, label = val_y)

  # Training and evaluating the model
  xgb_model <- xgb.train(params = list(objective = "binary:logistic"),
                         data = xgb_train, 
                         nrounds = rgrid[i, 1],
                         max_depth = rgrid[i, 2],
                         eta = rgrid[i, 3], 
                         subsample = rgrid[i, 4],
                         colsample_bytree = rgrid[i, 5],
                         gamma = rgrid[i, 6],
                         min_child_weight = rgrid[i, 7],
                         alpha = rgrid[i, 8],
                         lambda = rgrid[i, 9],
                         early_stopping_rounds = esr,
                         eval_metric = "auc",
                         watchlist = list(train = xgb_train, val = xgb_val),
                         verbose = FALSE,
                         nthread = 3
  )

  
# Predicting on the val set
phat <- predict(xgb_model, xgb_val, type = "prob")

  # Calculating the AUC
  pred_rocr <- prediction(phat, val_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc_tuning[p] <- auc_ROCR@y.values[[1]]
}
auc_runs[i] <- mean(auc_tuning)



 BI <- which.max(auc_runs) #best hyperparameter index
  best_AUC <- auc_runs[BI]
  best_params <- rgrid[BI, ]
  
  opt[j, 1] <- best_params[1, 1]
  opt[j, 2] <- best_params[1, 2]
  opt[j, 3] <- best_params[1, 3]
  opt[j, 4] <- best_params[1, 4]
  opt[j, 5] <- best_params[1, 5]
  opt[j, 6] <- best_params[1, 6]
  opt[j, 7] <- best_params[1, 7]
  opt[j, 8] <- best_params[1, 8]
  opt[j, 9] <- best_params[1, 9]
  opt[j, 10] <- max(auc_runs)
}

  # One-hot coding using R's `model.matrix`
  md_x <- model.matrix(~.+0, data = md[, -which(names(md) == "y")]) 
  md_y <- md$y
 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  test_y <- test$y
  
  # Preparing efficient matrix
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  
  
  
  # Training and evaluating the model
  xgb_mt <- xgb.train(params = list(objective = "binary:logistic"),
                         data = xgb_md, 
                         nrounds = opt[j ,1],
                         max_depth = opt[j ,2],
                         eta = opt[j ,3], 
                         subsample = opt[j ,4],
                         colsample_bytree = opt[j ,5],
                         gamma = opt[j ,6],
                         min_child_weight = opt[j ,7],
                         alpha = opt[j ,8],
                         lambda = opt[j ,9],
                         early_stopping_rounds = esr,
                         eval_metric = "auc",
                         watchlist = list(train = xgb_md, val = xgb_test),
                         verbose = FALSE,
                         nthread = 3
  )

  
# Predicting on the test set
phat <- predict(xgb_mt, xgb_test, type = "prob")

  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc_t <- auc_ROCR@y.values[[1]]



opt[j, 11] <- auc_t
  
}



end_time <- Sys.time()

elapsed_time <- end_time - start_time

elapsed_time
 


```
This code will index and assign the best hyper parameters from opt into a matrix called win. 

NOTE: A weakness is that the test run is one split or rather one n run. this means it is weak to a high standard deviation or variability in the models predicition. The issue is that if we want to be able to use multiple bootstrapped samples to get a average test run we will either risk overfitting the hyperparameters or will have to split the data in a awkward way.

Im want to do more reasearch on if there is a way boostrap samples for a average and not overfit the hyperparameters/model

This takes the top 50 percent of hyperparameters based on there 
```{r}

th <- quantile(opt[,11], probs = 0.50)
ind_opt <- which(opt[,11] >= th)

win <- opt[ind_opt, ]
win
```

This code is using bootstrapping and runs the best hyperparamters that we picked before. it tests the selected hyper parameters n times. since we are not tuning in it we can use all of the data in it.
```{r}
library(xgboost)
library(ROCR)

n <- 400
w <- nrow(win)
esr <- 10
#collums are hyper param set
bs_results <- matrix(0, nrow = n, ncol = w)



for (i in 1:n) {
  for (j in 1:w){
    auc <- c()
  #cat("loops: ", i, j, "\r")
  
  # Initial Split
  ind <- unique(sample(nrow(data), nrow(data), replace = TRUE))
  mdf<- data[ind, ]
  test <- data[-ind, ]
  
  # One-hot coding using R's `model.matrix`
  md_y <- mdf$y
  test_y <- test$y
  md_x <- model.matrix(~.+0, data = mdf[, -which(names(mdf) == "y")]) 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  
  # Preparing efficient matrix
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  # Training and evaluating the model
  xgb_m <- xgb.train(params = list(objective = "binary:logistic"),
                               data = xgb_md, 
                               nrounds = win[j, 1],
                               max_depth = win[j, 2],
                               eta = win[j, 3], 
                               subsample = win[j, 4],
                               colsample_bytree = win[j, 5],
                               gamma = win[j, 6],
                               min_child_weight = win[j, 7],
                               alpha = win[j, 8],
                               lambda = win[j, 9],
                               early_stopping_rounds = esr,
                               eval_metric = "auc",
                               watchlist = list(train = xgb_md, val = xgb_test),
                               verbose = FALSE,
                               nthread = 3
                              
  )
  
  # Predicting on the test set
  phat <- predict(xgb_m, xgb_test, type = "prob")
  
  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc <- auc_ROCR@y.values[[1]]
  
 bs_results[i, j] <- auc 
}
}
```

This code takes the colmeans of the matrix that gave our results. then we bind these results onto the win matrix for presentation. it also takes the index of the best run from before and saves the corelating hyperparameters into ww.
```{r}
bh_ind <- which.max(colMeans(bs_results))
ww <- win[bh_ind, ]
mean(bs_results[,bh_ind])
cm <- as.vector(colMeans(bs_results))
win <- cbind(win, av_ovr_n_runs=cm)
```



This is the final run. it uses bootrapping and runs n times.
```{r}
library(xgboost)
library(ROCR)

n <- 1000


esr <- 10


 auc <- c()
for (i in 1:n) {

   
  #cat("loops: ", i, "\r")
  
  # Initial Split This is bootstrapping
  ind <- unique(sample(nrow(data), nrow(data), replace = TRUE))
  mdf<- data[ind, ]
  test <- data[-ind, ]
  
  # One-hot coding using R's `model.matrix`
  md_y <- mdf$y
  test_y <- test$y
  md_x <- model.matrix(~.+0, data = mdf[, -which(names(mdf) == "y")]) 
  test_x <- model.matrix(~.+0, data = test[, -which(names(test) == "y")])
  
  # Preparing efficient matrix
  xgb_md <- xgb.DMatrix(data = md_x, label = md_y) 
  xgb_test <- xgb.DMatrix(data = test_x, label = test_y)
  
  # Modeling
  xgb_m <- xgb.train(params = list(objective = "binary:logistic"),
                               data = xgb_md, 
                               nrounds = ww[1],
                               max_depth = ww[2],
                               eta = ww[3], 
                               subsample = ww[4],
                               colsample_bytree = ww[5],
                               gamma = ww[6],
                               min_child_weight = ww[7],
                               alpha = ww[8],
                               lambda = ww[9],
                               early_stopping_rounds = esr,
                               eval_metric = "auc",
                               watchlist = list(train = xgb_md, val = xgb_test),
                               verbose = FALSE,
                               nthread = 3
                              
  )
  
  # Predicting on the test set
  phat <- predict(xgb_m, xgb_test, type = "prob")
  
  # Calculating the AUC
  pred_rocr <- prediction(phat, test_y)
  auc_ROCR <- performance(pred_rocr, measure = "auc")
  auc[i] <- auc_ROCR@y.values[[1]]
}
 
 mean(auc)
 sd(auc)
```

This presents the mean and 95% CI of the model runs
Note: we are representing individual observations/model runs so we use SD not SE.   
                             
```{r}

# plot auc and mean
plot(auc, col="red")
abline(a = mean(auc), b = 0, col = "blue", lwd = 2)
abline(a = mean(auc)-1.96*sd(auc), b = 0, col = "green", lwd = 3)
abline(a = mean(auc)+1.96*sd(auc), b = 0, col = "green", lwd = 3)

```

If we are finding a threshold he then need to pay attention to the watchlist outputs and tune nrounds accordingly
